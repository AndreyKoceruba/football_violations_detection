{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "import datetime\n",
    "import os\n",
    "import shutil\n",
    "import dill\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator\n",
    "from keras.applications.densenet import DenseNet121\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import GlobalAveragePooling2D, Dense, Dropout, Activation\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, TensorBoard\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, precision_recall_curve, auc\n",
    "from sklearn.neighbors.kde import KernelDensity\n",
    "from matplotlib import pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import plotly.offline as pyo\n",
    "pyo.init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "672e22eaa3a347749c63cf04ee932cca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='photos\\\\train\\\\0', max=199, style=ProgressStyle(description_wâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def clear_photos(dir_path):\n",
    "    for l in os.walk(dir_path):\n",
    "        i = 0\n",
    "        if len(l[2]) > 0:\n",
    "            for photo in tqdm_notebook(l[2], desc=l[0]):\\\n",
    "                os.remove(os.path.join(l[0], photo))\n",
    "\n",
    "clear_photos('photos')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Cut video to photos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def video_to_photos(input_file, output_dir):\n",
    "    cap = cv2.VideoCapture(input_file)\n",
    "    if cap.isOpened() == False:\n",
    "        raise Exception('Video stream doesn\\'t open!')\n",
    "    fps = np.round(cap.get(cv2.CAP_PROP_FPS), 0)\n",
    "    sample_size = 0\n",
    "    frame_num = 1\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if ret == True:\n",
    "            if frame_num % fps == 0:\n",
    "                cv2.imwrite('{}/{}.jpg'.format(output_dir, frame_num), frame)\n",
    "                sample_size += 1\n",
    "        else:\n",
    "            break\n",
    "        frame_num += 1\n",
    "        print('\\rProgress: {}'.format(frame_num), end='')\n",
    "    cap.release()\n",
    "    print()\n",
    "    return sample_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 60422\n",
      "Stage \"train, 0\" has done\n",
      "Progress: 32164\n",
      "Stage \"train, 1\" has done\n",
      "Progress: 49990\n",
      "Stage \"valid, 0\" has done\n",
      "Progress: 33042\n",
      "Stage \"valid, 1\" has done\n",
      "Progress: 48774\n",
      "Stage \"test, 0\" has done\n",
      "Progress: 31053\n",
      "Stage \"test, 1\" has done\n"
     ]
    }
   ],
   "source": [
    "samples = ('train', 'valid', 'test')\n",
    "classes = ('0', '1')\n",
    "photos_cnt = dict()\n",
    "for s in samples:\n",
    "    for c in classes:\n",
    "        input_file = 'videos/input/{}/{}/video.mp4'.format(s, c)\n",
    "        output_dir = 'photos/{}/{}'.format(s, c)\n",
    "        photos_cnt['{}/{}'.format(s, c)] = video_to_photos(input_file, output_dir)\n",
    "        print('Stage \"{}, {}\" has done'.format(s, c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3473752430330525\n",
      "0.3979038670039754\n",
      "0.3890977443609023\n"
     ]
    }
   ],
   "source": [
    "print(photos_cnt['train/1'] / (photos_cnt['train/0'] + photos_cnt['train/1']))\n",
    "print(photos_cnt['valid/1'] / (photos_cnt['valid/0'] + photos_cnt['valid/1']))\n",
    "print(photos_cnt['test/1'] / (photos_cnt['test/0'] + photos_cnt['test/1']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. DataGen Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_image(image):\n",
    "    image /= 255\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "#     brightness_range=[0.2, 1.8],\n",
    "    zoom_range=[0.15, 1.15],\n",
    "    horizontal_flip=True,\n",
    "    preprocessing_function=preprocessing_image\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_size = (224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3086 images belonging to 2 classes.\n",
      "Found 2767 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = datagen.flow_from_directory(\n",
    "    'photos/train',\n",
    "    batch_size=16,\n",
    "    target_size=target_size,\n",
    "    class_mode='binary',\n",
    "    seed=1992\n",
    ")\n",
    "valid_datagen = datagen.flow_from_directory(\n",
    "    'photos/valid',\n",
    "    batch_size=16,\n",
    "    target_size=target_size,\n",
    "    class_mode='binary',\n",
    "    seed=1992\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\akoceruba\\Anaconda3\\envs\\python3.6.6\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "densenet = DenseNet121(\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    input_shape=(224,224,3)\n",
    ")\n",
    "# densenet.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\akoceruba\\Anaconda3\\envs\\python3.6.6\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "densenet121 (Model)          (None, 7, 7, 1024)        7037504   \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               262400    \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 257       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 7,300,161\n",
      "Trainable params: 7,216,513\n",
      "Non-trainable params: 83,648\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(densenet)\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dense(256))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(Adam(), loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(filepath='model/checkpoint_best_model.h5', verbose=1, save_best_only=True)\n",
    "early_stopping = EarlyStopping(patience=5, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(patience=2, factor=0.5)\n",
    "# tensorboard = TensorBoard(log_dir='logs/tensorboard', histogram_freq=2, update_freq='batch')\n",
    "callbacks = [checkpoint, early_stopping, reduce_lr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\akoceruba\\Anaconda3\\envs\\python3.6.6\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/1000\n",
      " - 81s - loss: 0.3584 - val_loss: 1.5288\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.52875, saving model to model/checkpoint_best_model.h5\n",
      "Epoch 2/1000\n",
      " - 54s - loss: 0.2441 - val_loss: 1.4233\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.52875 to 1.42328, saving model to model/checkpoint_best_model.h5\n",
      "Epoch 3/1000\n",
      " - 54s - loss: 0.2277 - val_loss: 0.8037\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.42328 to 0.80367, saving model to model/checkpoint_best_model.h5\n",
      "Epoch 4/1000\n",
      " - 53s - loss: 0.2334 - val_loss: 2.0686\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.80367\n",
      "Epoch 5/1000\n",
      " - 53s - loss: 0.1908 - val_loss: 0.4568\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.80367 to 0.45683, saving model to model/checkpoint_best_model.h5\n",
      "Epoch 6/1000\n",
      " - 53s - loss: 0.1783 - val_loss: 0.4438\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.45683 to 0.44381, saving model to model/checkpoint_best_model.h5\n",
      "Epoch 7/1000\n",
      " - 53s - loss: 0.1538 - val_loss: 0.5558\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.44381\n",
      "Epoch 8/1000\n",
      " - 53s - loss: 0.1593 - val_loss: 0.9332\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.44381\n",
      "Epoch 9/1000\n",
      " - 53s - loss: 0.1228 - val_loss: 0.4681\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.44381\n",
      "Epoch 10/1000\n",
      " - 53s - loss: 0.0949 - val_loss: 0.7878\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.44381\n",
      "Epoch 11/1000\n",
      " - 53s - loss: 0.0832 - val_loss: 0.6888\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.44381\n",
      "Epoch 00011: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(\n",
    "    generator=train_datagen,\n",
    "    steps_per_epoch=int(np.ceil(train_datagen.samples / train_datagen.batch_size)),\n",
    "    verbose=2,\n",
    "    epochs=1000,\n",
    "    callbacks=callbacks,\n",
    "    validation_data=valid_datagen,\n",
    "    validation_steps=int(np.ceil(valid_datagen.samples / valid_datagen.batch_size)),\n",
    "    workers=8,\n",
    "#     use_multiprocessing=True,\n",
    "#     class_weight={\n",
    "#         0: 1.0,\n",
    "#         1: 60422 / 32164\n",
    "#     }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model/history.pkl', 'wb') as f:\n",
    "    dill.dump(history, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('model/history.pkl', 'rb') as f:\n",
    "#     history = dill.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Validation Curves "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'learning_curves.html'"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loss = go.Scatter(\n",
    "    x=list(range(1, len(history.history['loss']) + 1)),\n",
    "    y=history.history['loss'],\n",
    "    mode='lines+markers',\n",
    "    name='Train loss',\n",
    "    hoverinfo='y'\n",
    ")\n",
    "val_loss = go.Scatter(\n",
    "    x=list(range(1, len(history.history['val_loss']) + 1)),\n",
    "    y=history.history['val_loss'],\n",
    "    mode='lines+markers',\n",
    "    name='Validation loss',\n",
    "    hoverinfo='y'\n",
    ")\n",
    "\n",
    "data = [train_loss, val_loss]\n",
    "layout = go.Layout(\n",
    "    title=dict(\n",
    "        text='Learning curves'\n",
    "    )\n",
    ")\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "\n",
    "# fig.show()\n",
    "pyo.plot(fig, filename='learning_curves.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('model/checkpoint_best_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_test_batch(test_dir, target_img_size, batch_size=256):\n",
    "#     for class_name in os.listdir(test_dir):\n",
    "#         test_dir_class = os.path.join(test_dir, class_name)\n",
    "#         image_names = []\n",
    "#         true_labels = []\n",
    "#         batch = []\n",
    "#         images = os.listdir(test_dir_class)\n",
    "#         for i in range(len(images)):\n",
    "#             test_dir_class_image = os.path.join(test_dir_class, images[i])\n",
    "#             img = load_img(test_dir_class_image)\n",
    "#             img = img_to_array(img)\n",
    "#             img = cv2.resize(img, target_img_size)\n",
    "#             img = preprocessing_image(img)\n",
    "#             image_names.append(images[i][:-4])\n",
    "#             true_labels.append(class_name)\n",
    "#             batch.append(img)\n",
    "#             if (i + 1) % batch_size == 0 or i == len(images) - 1:\n",
    "#                 yield {\n",
    "#                     'image_names': image_names,\n",
    "#                     'true_labels': true_labels,\n",
    "#                     'batch': np.array(batch)\n",
    "#                 }\n",
    "#                 image_names = []\n",
    "#                 true_labels = []\n",
    "#                 batch = []\n",
    "\n",
    "# test_dir = 'photos/test/'\n",
    "# get_test_batch_gen = get_test_batch(test_dir, target_size)\n",
    "\n",
    "# image_names = []\n",
    "# y_true = []\n",
    "# y_pred = []\n",
    "# for batch in tqdm_notebook(get_test_batch_gen):\n",
    "#     image_names.extend(batch['image_names'])\n",
    "#     y_true.extend(list(map(int, batch['true_labels'])))\n",
    "#     y_pred.extend(list(model.predict_on_batch(batch['batch']).ravel()))\n",
    "# predictions = [image_names, y_true, y_pred]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. ROC and PR curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen_inference = ImageDataGenerator(\n",
    "    preprocessing_function=preprocessing_image\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark(func):\n",
    "    import time\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start_time = time.time()\n",
    "        res = func(*args, **kwargs)\n",
    "        end_time = time.time()\n",
    "        delta = end_time - start_time\n",
    "        minutes = int(delta / 60)\n",
    "        seconds = int(delta - minutes * 60)\n",
    "        print('Time of \"{}\": {} min. {} sec.'.format(func.__name__, minutes, seconds))\n",
    "        return res\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "@benchmark\n",
    "def predict(model, datagen, directory, batch_size=256, target_size=(224, 224), workers=16):\n",
    "    inference = datagen.flow_from_directory(\n",
    "        directory,\n",
    "        batch_size=batch_size,\n",
    "        target_size=target_size,\n",
    "        class_mode='binary',\n",
    "        shuffle=False,\n",
    "        seed=1992\n",
    "    )\n",
    "    image_names = list(map(lambda x: x[2:-4], inference.filenames))\n",
    "    y_true = inference.classes\n",
    "    y_pred = model.predict_generator(\n",
    "        inference,\n",
    "        steps=int(np.ceil(inference.samples / inference.batch_size)),\n",
    "        workers=12,\n",
    "        verbose=1\n",
    "    ).ravel()\n",
    "    return image_names, y_true, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3086 images belonging to 2 classes.\n",
      "13/13 [==============================] - ETA: 3: - ETA: 1: - ETA: 1: - ETA: 44s - ETA: 32 - ETA: 24 - ETA: 18 - ETA: 13 - ETA: 10 - ETA: 7 - ETA:  - ETA:  - 25s 2s/step\n",
      "Time of \"predict\": 0 min. 25 sec.\n",
      "Found 2767 images belonging to 2 classes.\n",
      "11/11 [==============================] - ETA: 3: - ETA: 1: - ETA: 53s - ETA: 36 - ETA: 25 - ETA: 18 - ETA: 13 - ETA: 8 - ETA:  - ETA:  - 29s 3s/step\n",
      "Time of \"predict\": 0 min. 29 sec.\n",
      "Found 2660 images belonging to 2 classes.\n",
      "11/11 [==============================] - ETA: 2: - ETA: 1: - ETA: 46s - ETA: 31 - ETA: 22 - ETA: 16 - ETA: 11 - ETA: 7 - ETA:  - ETA:  - 24s 2s/step\n",
      "Time of \"predict\": 0 min. 24 sec.\n"
     ]
    }
   ],
   "source": [
    "image_names_train, y_train_true, y_train_pred = predict(model, datagen_inference, 'photos/train')\n",
    "\n",
    "with open('predictions_train.pkl', 'wb') as f:\n",
    "    dill.dump([image_names_train, y_train_true, y_train_pred], f)\n",
    "\n",
    "image_names_valid, y_valid_true, y_valid_pred = predict(model, datagen_inference, 'photos/valid')\n",
    "\n",
    "with open('predictions_valid.pkl', 'wb') as f:\n",
    "    dill.dump([image_names_valid, y_valid_true, y_valid_pred], f)\n",
    "\n",
    "image_names_test, y_test_true, y_test_pred = predict(model, datagen_inference, 'photos/test')\n",
    "\n",
    "with open('predictions_test.pkl', 'wb') as f:\n",
    "    dill.dump([image_names_test, y_test_true, y_test_pred], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini_score(roc_auc):\n",
    "    return 2 * roc_auc - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ROC AUC and GINI:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.9961097874579437"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.9922195749158873"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "roc_auc = roc_auc_score(y_train_true, y_train_pred)\n",
    "gini = gini_score(roc_auc)\n",
    "display('ROC AUC and GINI:', roc_auc, gini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ROC AUC and GINI:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.9300213273320227"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.8600426546640454"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "roc_auc = roc_auc_score(y_valid_true, y_valid_pred)\n",
    "gini = gini_score(roc_auc)\n",
    "display('ROC AUC and GINI:', roc_auc, gini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ROC AUC and GINI:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.91812292827945"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.8362458565588999"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "roc_auc = roc_auc_score(y_test_true, y_test_pred)\n",
    "gini = gini_score(roc_auc)\n",
    "display('ROC AUC and GINI:', roc_auc, gini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_curves(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    threshold_train,\n",
    "    x_valid,\n",
    "    y_valid,\n",
    "    threshold_valid,\n",
    "    x_test,\n",
    "    y_test,\n",
    "    threshold_test,\n",
    "    curve_type='ROC',\n",
    "    width=666,\n",
    "    height=666\n",
    "):\n",
    "    \n",
    "    trace_train = go.Scatter(\n",
    "        x=x_train,\n",
    "        y=y_train,\n",
    "        mode='lines',\n",
    "        name='Train',\n",
    "        text=threshold_train\n",
    "    )\n",
    "    \n",
    "    trace_valid = go.Scatter(\n",
    "        x=x_valid,\n",
    "        y=y_valid,\n",
    "        mode='lines',\n",
    "        name='Valid',\n",
    "        text=threshold_valid\n",
    "    )\n",
    "    \n",
    "    trace_test = go.Scatter(\n",
    "        x=x_test,\n",
    "        y=y_test,\n",
    "        mode='lines',\n",
    "        name='Test',\n",
    "        text=threshold_test\n",
    "    )\n",
    "\n",
    "    data = [trace_train, trace_valid, trace_test]\n",
    "    \n",
    "    if curve_type == 'ROC':\n",
    "        \n",
    "        x_title = 'FPR'\n",
    "        y_title = 'TPR'\n",
    "        title = 'ROC Curves'\n",
    "        \n",
    "        trace_dot = go.Scatter(\n",
    "            x=[0, 1],\n",
    "            y=[0, 1],\n",
    "            mode='lines',\n",
    "            showlegend=False,\n",
    "            line=dict(\n",
    "                dash='dot'\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        data.append(trace_dot)\n",
    "        \n",
    "    elif curve_type == 'PR':\n",
    "        \n",
    "        x_title = 'Recall'\n",
    "        y_title = 'Precision'\n",
    "        title = 'PR Curves'\n",
    "    \n",
    "    layout = go.Layout(\n",
    "        title=dict(\n",
    "            text=title\n",
    "        ),\n",
    "        hovermode='closest',\n",
    "        width=width,\n",
    "        height=height,\n",
    "        xaxis=dict(\n",
    "            title=dict(\n",
    "                text=x_title\n",
    "            )\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            title=dict(\n",
    "                text=y_title\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    fig = go.Figure(data=data, layout=layout)\n",
    "\n",
    "#     fig.show()\n",
    "    pyo.plot(fig, filename='{}_curves.html'.format(curve_type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_train, tpr_train, roc_thresholds_train = roc_curve(y_train_true, y_train_pred)\n",
    "fpr_valid, tpr_valid, roc_thresholds_valid = roc_curve(y_valid_true, y_valid_pred)\n",
    "fpr_test, tpr_test, roc_thresholds_test = roc_curve(y_test_true, y_test_pred)\n",
    "plot_curves(\n",
    "    fpr_train,\n",
    "    tpr_train,\n",
    "    roc_thresholds_train,\n",
    "    fpr_valid,\n",
    "    tpr_valid,\n",
    "    roc_thresholds_valid,\n",
    "    fpr_test,\n",
    "    tpr_test,\n",
    "    roc_thresholds_test\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_train, precision_train, pr_thresholds_train = precision_recall_curve(y_train_true, y_train_pred)\n",
    "recall_valid, precision_valid, pr_thresholds_valid = precision_recall_curve(y_valid_true, y_valid_pred)\n",
    "recall_test, precision_test, pr_thresholds_test = precision_recall_curve(y_test_true, y_test_pred)\n",
    "plot_curves(\n",
    "    recall_train,\n",
    "    precision_train,\n",
    "    pr_thresholds_train,\n",
    "    recall_valid,\n",
    "    precision_valid,\n",
    "    pr_thresholds_valid,\n",
    "    recall_test,\n",
    "    precision_test,\n",
    "    pr_thresholds_test,\n",
    "    curve_type='PR'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PR Train: 0.26858177933332306\n",
      "PR Valid: 0.4958372711727005\n",
      "PR Test: 0.3165157198142953\n"
     ]
    }
   ],
   "source": [
    "print('PR Train:', auc(recall_train, precision_train, reorder=True))\n",
    "print('PR Valid:', auc(recall_valid, precision_valid, reorder=True))\n",
    "print('PR Test:', auc(recall_test, precision_test, reorder=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Video Markup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_times_predictions_to_csv(times, predictions, filename):\n",
    "    if len(times) != len(predictions):\n",
    "        raise Exception('Arrays have different length! Times: {}, Predictions: {}'.format(len(times), len(predictions)))\n",
    "    else:\n",
    "        with open(filename, 'a') as f:\n",
    "            for i in range(len(times)):\n",
    "                f.write('{},{}\\n'.format(times[i], predictions[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 182014 ... Done!\n",
      "Wall time: 44min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "input_file = 'videos/raw/valid/0/Real Madrid CF vs FC Barcelona  2-3  Full Match 23-04-17 HD.mp4'\n",
    "output_file = 'time_and_predictions.csv'\n",
    "batch_size = 512\n",
    "\n",
    "cap = cv2.VideoCapture(input_file)\n",
    "if cap.isOpened() == False:\n",
    "    raise Exception('Video stream doesn\\'t open!')\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "frame_num = 0\n",
    "times = []\n",
    "batch = []\n",
    "try:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if ret == True:\n",
    "            times.append(frame_num / fps)\n",
    "            frame = img_to_array(frame)\n",
    "            frame = cv2.resize(frame, target_size)\n",
    "            frame = preprocessing_image(frame)\n",
    "            batch.append(frame)\n",
    "            if (frame_num + 1) % batch_size == 0:\n",
    "                batch = np.array(batch)\n",
    "                predictions = list(model.predict_on_batch(batch).ravel())\n",
    "                append_times_predictions_to_csv(times, predictions, output_file)\n",
    "                times = []\n",
    "                batch = []\n",
    "            print('\\rProgress: {}'.format(frame_num), end='')\n",
    "            frame_num += 1\n",
    "        else:\n",
    "            batch = np.array(batch)\n",
    "            predictions = list(model.predict_on_batch(batch).ravel())\n",
    "            append_times_predictions_to_csv(times, predictions, output_file)\n",
    "            print(' ... Done!')\n",
    "            break\n",
    "finally:\n",
    "    cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.033367</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.066733</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.100100</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.133467</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0    1\n",
       "0  0.000000  1.0\n",
       "1  0.033367  1.0\n",
       "2  0.066733  1.0\n",
       "3  0.100100  1.0\n",
       "4  0.133467  1.0"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('time_and_predictions.csv', header=None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(182015, 2)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['time', 'prediction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>prediction</th>\n",
       "      <th>second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.033367</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.066733</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.100100</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.133467</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       time  prediction  second\n",
       "0  0.000000         1.0       0\n",
       "1  0.033367         1.0       0\n",
       "2  0.066733         1.0       0\n",
       "3  0.100100         1.0       0\n",
       "4  0.133467         1.0       0"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['second'] = df['time'].astype(int)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>second</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.976879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.950476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.999103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.547093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.098557</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   second  prediction\n",
       "0       0    0.976879\n",
       "1       1    0.950476\n",
       "2       2    0.999103\n",
       "3       3    0.547093\n",
       "4       4    0.098557"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_seconds = df.groupby(['second'])[['prediction']].mean().reset_index()\n",
    "df_seconds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>second</th>\n",
       "      <th>prediction</th>\n",
       "      <th>hms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.976879</td>\n",
       "      <td>0:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.950476</td>\n",
       "      <td>0:00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.999103</td>\n",
       "      <td>0:00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.547093</td>\n",
       "      <td>0:00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.098557</td>\n",
       "      <td>0:00:04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   second  prediction      hms\n",
       "0       0    0.976879  0:00:00\n",
       "1       1    0.950476  0:00:01\n",
       "2       2    0.999103  0:00:02\n",
       "3       3    0.547093  0:00:03\n",
       "4       4    0.098557  0:00:04"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_seconds['hms'] = df_seconds['second'].apply(lambda x: str(datetime.timedelta(seconds=x)))\n",
    "df_seconds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'violation_distribution.html'"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trace = go.Scatter(\n",
    "    x=df_seconds['hms'],\n",
    "    y=df_seconds['prediction']\n",
    ")\n",
    "data = [trace]\n",
    "layout = go.Layout(\n",
    "    title=dict(\n",
    "        text='Violation distribution'\n",
    "    ),\n",
    "    xaxis=dict(\n",
    "        title=dict(\n",
    "            text='Second'\n",
    "        )\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title=dict(\n",
    "            text='Average score per second'\n",
    "        )\n",
    "    )\n",
    ")\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "pyo.plot(fig, filename='violation_distribution.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.6",
   "language": "python",
   "name": "python3.6.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
