{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "import os\n",
    "import shutil\n",
    "import dill\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator\n",
    "from keras.applications.densenet import DenseNet121\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import GlobalAveragePooling2D, Dense, Dropout, Activation\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, TensorBoard\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, precision_recall_curve, auc\n",
    "from matplotlib import pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import plotly.offline as pyo\n",
    "pyo.init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Cut video to photos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def video_to_photos(input_file, output_dir):\n",
    "    cap = cv2.VideoCapture(input_file)\n",
    "    if cap.isOpened() == False:\n",
    "        raise Exception('Video stream doesn\\'t open!')\n",
    "    frame_num = 1\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if ret == True:\n",
    "            cv2.imwrite('{}/{}.jpg'.format(output_dir, frame_num), frame)\n",
    "        else:\n",
    "            break\n",
    "        frame_num += 1\n",
    "        print('\\rProgress: {}'.format(frame_num), end='')\n",
    "    cap.release()\n",
    "    print()\n",
    "    return frame_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 60422Stage \"train, 0\" has done\n",
      "Progress: 32164Stage \"train, 1\" has done\n",
      "Progress: 49990Stage \"valid, 0\" has done\n",
      "Progress: 33042Stage \"valid, 1\" has done\n",
      "Progress: 48774Stage \"test, 0\" has done\n",
      "Progress: 31053Stage \"test, 1\" has done\n"
     ]
    }
   ],
   "source": [
    "samples = ('train', 'valid', 'test')\n",
    "classes = ('0', '1')\n",
    "photos_cnt = dict()\n",
    "for s in samples:\n",
    "    for c in classes:\n",
    "        input_file = 'videos/input/{}/{}/video.mp4'.format(s, c)\n",
    "        output_dir = 'photos/{}/{}'.format(s, c)\n",
    "        photos_cnt['{}/{}'.format(s, c)] = video_to_photos(input_file, output_dir)\n",
    "        print('Stage \"{}, {}\" has done'.format(s, c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.34739593459054285\n",
      "0.39794296174968685\n",
      "0.38900372054568005\n"
     ]
    }
   ],
   "source": [
    "print(photos_cnt['train/1'] / (photos_cnt['train/0'] + photos_cnt['train/1']))\n",
    "print(photos_cnt['valid/1'] / (photos_cnt['valid/0'] + photos_cnt['valid/1']))\n",
    "print(photos_cnt['test/1'] / (photos_cnt['test/0'] + photos_cnt['test/1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_image(image):\n",
    "    image /= 255\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "#     brightness_range=[0.2, 1.8],\n",
    "    zoom_range=[0.15, 1.15],\n",
    "    horizontal_flip=True,\n",
    "    preprocessing_function=preprocessing_image\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_size = (224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 92584 images belonging to 2 classes.\n",
      "Found 83030 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = datagen.flow_from_directory(\n",
    "    'photos/train',\n",
    "    batch_size=128,\n",
    "    target_size=target_size,\n",
    "    class_mode='binary',\n",
    "    seed=1992\n",
    ")\n",
    "valid_datagen = datagen.flow_from_directory(\n",
    "    'photos/valid',\n",
    "    batch_size=128,\n",
    "    target_size=target_size,\n",
    "    class_mode='binary',\n",
    "    seed=1992\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\akoceruba\\Anaconda3\\envs\\python3.6.6\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "densenet = DenseNet121(\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    input_shape=(224,224,3)\n",
    ")\n",
    "densenet.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\akoceruba\\Anaconda3\\envs\\python3.6.6\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "densenet121 (Model)          (None, 7, 7, 1024)        7037504   \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               262400    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 257       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1)                 0         \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 7,300,161\n",
      "Trainable params: 262,657\n",
      "Non-trainable params: 7,037,504\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(densenet)\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dense(256))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(1))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(Adam(), loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(filepath='model/checkpoint_best_model.h5', verbose=1, save_best_only=True)\n",
    "early_stopping = EarlyStopping(patience=5, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(patience=2, factor=0.5)\n",
    "# tensorboard = TensorBoard(log_dir='logs/tensorboard', histogram_freq=2, update_freq='batch')\n",
    "callbacks = [checkpoint, early_stopping, reduce_lr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\akoceruba\\Anaconda3\\envs\\python3.6.6\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/1000\n",
      " - 1133s - loss: 0.4807 - val_loss: 0.5367\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.53672, saving model to model/checkpoint_best_model.h5\n",
      "Epoch 2/1000\n",
      " - 1091s - loss: 0.3801 - val_loss: 0.6295\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.53672\n",
      "Epoch 3/1000\n",
      " - 1103s - loss: 0.3636 - val_loss: 0.5982\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.53672\n",
      "Epoch 4/1000\n",
      " - 1222s - loss: 0.3427 - val_loss: 0.6543\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.53672\n",
      "Epoch 5/1000\n",
      " - 1108s - loss: 0.3365 - val_loss: 0.6622\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.53672\n",
      "Epoch 6/1000\n",
      " - 1190s - loss: 0.3277 - val_loss: 0.5670\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.53672\n",
      "Epoch 00006: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(\n",
    "    generator=train_datagen,\n",
    "    steps_per_epoch=int(np.ceil(train_datagen.samples / train_datagen.batch_size)),\n",
    "    verbose=2,\n",
    "    epochs=1000,\n",
    "    callbacks=callbacks,\n",
    "    validation_data=valid_datagen,\n",
    "    validation_steps=int(np.ceil(valid_datagen.samples / valid_datagen.batch_size)),\n",
    "    workers=8,\n",
    "#     use_multiprocessing=True,\n",
    "    class_weight={\n",
    "        0: 1.0,\n",
    "        1: 60422 / 32164\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model/history.pkl', 'wb') as f:\n",
    "    dill.dump(history, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\akoceruba\\Anaconda3\\envs\\python3.6.6\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\akoceruba\\Anaconda3\\envs\\python3.6.6\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\Users\\akoceruba\\Anaconda3\\envs\\python3.6.6\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akoceruba\\Anaconda3\\envs\\python3.6.6\\lib\\site-packages\\keras\\engine\\saving.py:350: UserWarning:\n",
      "\n",
      "Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# with open('model/history.pkl', 'rb') as f:\n",
    "#     history = dill.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'learning_curves.html'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loss = go.Scatter(\n",
    "    x=list(range(1, len(history.history['loss']) + 1)),\n",
    "    y=history.history['loss'],\n",
    "    mode='lines+markers',\n",
    "    name='Train loss',\n",
    "    hoverinfo='y'\n",
    ")\n",
    "val_loss = go.Scatter(\n",
    "    x=list(range(1, len(history.history['val_loss']) + 1)),\n",
    "    y=history.history['val_loss'],\n",
    "    mode='lines+markers',\n",
    "    name='Validation loss',\n",
    "    hoverinfo='y'\n",
    ")\n",
    "\n",
    "data = [train_loss, val_loss]\n",
    "layout = go.Layout(\n",
    "    title=dict(\n",
    "        text='Learning curves'\n",
    "    )\n",
    ")\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "\n",
    "# fig.show()\n",
    "pyo.plot(fig, filename='learning_curves.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\akoceruba\\Anaconda3\\envs\\python3.6.6\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\akoceruba\\Anaconda3\\envs\\python3.6.6\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\Users\\akoceruba\\Anaconda3\\envs\\python3.6.6\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akoceruba\\Anaconda3\\envs\\python3.6.6\\lib\\site-packages\\keras\\engine\\saving.py:350: UserWarning:\n",
      "\n",
      "Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = load_model('model/checkpoint_best_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_test_batch(test_dir, target_img_size, batch_size=256):\n",
    "#     for class_name in os.listdir(test_dir):\n",
    "#         test_dir_class = os.path.join(test_dir, class_name)\n",
    "#         image_names = []\n",
    "#         true_labels = []\n",
    "#         batch = []\n",
    "#         images = os.listdir(test_dir_class)\n",
    "#         for i in range(len(images)):\n",
    "#             test_dir_class_image = os.path.join(test_dir_class, images[i])\n",
    "#             img = load_img(test_dir_class_image)\n",
    "#             img = img_to_array(img)\n",
    "#             img = cv2.resize(img, target_img_size)\n",
    "#             img = preprocessing_image(img)\n",
    "#             image_names.append(images[i][:-4])\n",
    "#             true_labels.append(class_name)\n",
    "#             batch.append(img)\n",
    "#             if (i + 1) % batch_size == 0 or i == len(images) - 1:\n",
    "#                 yield {\n",
    "#                     'image_names': image_names,\n",
    "#                     'true_labels': true_labels,\n",
    "#                     'batch': np.array(batch)\n",
    "#                 }\n",
    "#                 image_names = []\n",
    "#                 true_labels = []\n",
    "#                 batch = []\n",
    "\n",
    "# test_dir = 'photos/test/'\n",
    "# get_test_batch_gen = get_test_batch(test_dir, target_size)\n",
    "\n",
    "# image_names = []\n",
    "# y_true = []\n",
    "# y_pred = []\n",
    "# for batch in tqdm_notebook(get_test_batch_gen):\n",
    "#     image_names.extend(batch['image_names'])\n",
    "#     y_true.extend(list(map(int, batch['true_labels'])))\n",
    "#     y_pred.extend(list(model.predict_on_batch(batch['batch']).ravel()))\n",
    "# predictions = [image_names, y_true, y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen_inference = ImageDataGenerator(\n",
    "    preprocessing_function=preprocessing_image\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark(func):\n",
    "    import time\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start_time = time.time()\n",
    "        res = func(*args, **kwargs)\n",
    "        end_time = time.time()\n",
    "        delta = end_time - start_time\n",
    "        minutes = int(delta / 60)\n",
    "        seconds = int(delta - minutes * 60)\n",
    "        print('Time of \"{}\": {} min. {} sec.'.format(func.__name__, minutes, seconds))\n",
    "        return res\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "@benchmark\n",
    "def predict(model, datagen, directory, batch_size=256, target_size=(224, 224), workers=16):\n",
    "    inference = datagen.flow_from_directory(\n",
    "        directory,\n",
    "        batch_size=batch_size,\n",
    "        target_size=target_size,\n",
    "        class_mode='binary',\n",
    "        shuffle=False,\n",
    "        seed=1992\n",
    "    )\n",
    "    image_names = list(map(lambda x: x[2:-4], inference.filenames))\n",
    "    y_true = inference.classes\n",
    "    y_pred = model.predict_generator(\n",
    "        inference,\n",
    "        steps=int(np.ceil(inference.samples / inference.batch_size)),\n",
    "        workers=12,\n",
    "        verbose=1\n",
    "    ).ravel()\n",
    "    return image_names, y_true, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 92584 images belonging to 2 classes.\n",
      "362/362 [==============================] - ETA: 1:21:3 - ETA: 42:36  - ETA: 29:3 - ETA: 23:0 - ETA: 19:1 - ETA: 16:3 - ETA: 14:4 - ETA: 13:2 - ETA: 12:1 - ETA: 11:2 - ETA: 10:4 - ETA: 10:0 - ETA: 9:3 - ETA: 9: - ETA: 9: - ETA: 9: - ETA: 9: - ETA: 9: - ETA: 9: - ETA: 8: - ETA: 8: - ETA: 8: - ETA: 8: - ETA: 8: - ETA: 7: - ETA: 7: - ETA: 7: - ETA: 7: - ETA: 7: - ETA: 7: - ETA: 7: - ETA: 7: - ETA: 7: - ETA: 7: - ETA: 7: - ETA: 7: - ETA: 7: - ETA: 7: - ETA: 6: - ETA: 6: - ETA: 6: - ETA: 6: - ETA: 6: - ETA: 6: - ETA: 6: - ETA: 6: - ETA: 6: - ETA: 6: - ETA: 6: - ETA: 6: - ETA: 6: - ETA: 6: - ETA: 6: - ETA: 6: - ETA: 6: - ETA: 6: - ETA: 6: - ETA: 6: - ETA: 6: - ETA: 6: - ETA: 6: - ETA: 6: - ETA: 6: - ETA: 6: - ETA: 5: - ETA: 6: - ETA: 6: - ETA: 6: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 59s - ETA: 58 - ETA: 57 - ETA: 56 - ETA: 55 - ETA: 54 - ETA: 52 - ETA: 51 - ETA: 50 - ETA: 49 - ETA: 48 - ETA: 47 - ETA: 46 - ETA: 45 - ETA: 44 - ETA: 42 - ETA: 41 - ETA: 40 - ETA: 39 - ETA: 38 - ETA: 37 - ETA: 36 - ETA: 35 - ETA: 33 - ETA: 32 - ETA: 31 - ETA: 30 - ETA: 29 - ETA: 28 - ETA: 27 - ETA: 26 - ETA: 25 - ETA: 24 - ETA: 22 - ETA: 21 - ETA: 20 - ETA: 19 - ETA: 18 - ETA: 17 - ETA: 16 - ETA: 15 - ETA: 14 - ETA: 13 - ETA: 12 - ETA: 10 - ETA: 9 - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - 395s 1s/step\n",
      "Time of \"predict\": 6 min. 38 sec.\n",
      "Found 83030 images belonging to 2 classes.\n",
      "325/325 [==============================] - ETA: 1:18:3 - ETA: 40:55  - ETA: 28:2 - ETA: 22:0 - ETA: 18:2 - ETA: 15:4 - ETA: 14:0 - ETA: 12:4 - ETA: 11:3 - ETA: 10:4 - ETA: 10:0 - ETA: 9:3 - ETA: 9: - ETA: 8: - ETA: 9: - ETA: 8: - ETA: 8: - ETA: 8: - ETA: 8: - ETA: 8: - ETA: 7: - ETA: 7: - ETA: 7: - ETA: 7: - ETA: 7: - ETA: 6: - ETA: 7: - ETA: 7: - ETA: 7: - ETA: 6: - ETA: 6: - ETA: 6: - ETA: 6: - ETA: 6: - ETA: 6: - ETA: 6: - ETA: 6: - ETA: 6: - ETA: 6: - ETA: 6: - ETA: 6: - ETA: 6: - ETA: 6: - ETA: 6: - ETA: 6: - ETA: 6: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 2: - ETA: 3: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 59s - ETA: 58 - ETA: 56 - ETA: 55 - ETA: 54 - ETA: 53 - ETA: 52 - ETA: 51 - ETA: 50 - ETA: 49 - ETA: 48 - ETA: 47 - ETA: 45 - ETA: 44 - ETA: 43 - ETA: 42 - ETA: 41 - ETA: 40 - ETA: 39 - ETA: 38 - ETA: 37 - ETA: 36 - ETA: 34 - ETA: 33 - ETA: 32 - ETA: 31 - ETA: 30 - ETA: 29 - ETA: 28 - ETA: 27 - ETA: 26 - ETA: 25 - ETA: 24 - ETA: 22 - ETA: 21 - ETA: 20 - ETA: 19 - ETA: 18 - ETA: 17 - ETA: 16 - ETA: 15 - ETA: 14 - ETA: 12 - ETA: 11 - ETA: 10 - ETA: 9 - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - 349s 1s/step\n",
      "Time of \"predict\": 5 min. 54 sec.\n",
      "Found 79825 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "312/312 [==============================] - ETA: 1:21:2 - ETA: 42:54  - ETA: 29:3 - ETA: 23:0 - ETA: 19:0 - ETA: 16:2 - ETA: 14:2 - ETA: 13:0 - ETA: 11:5 - ETA: 11:0 - ETA: 10:2 - ETA: 9:4 - ETA: 9: - ETA: 9: - ETA: 8: - ETA: 8: - ETA: 8: - ETA: 8: - ETA: 8: - ETA: 8: - ETA: 7: - ETA: 7: - ETA: 7: - ETA: 7: - ETA: 7: - ETA: 7: - ETA: 7: - ETA: 7: - ETA: 6: - ETA: 6: - ETA: 6: - ETA: 6: - ETA: 6: - ETA: 6: - ETA: 6: - ETA: 6: - ETA: 6: - ETA: 6: - ETA: 6: - ETA: 6: - ETA: 6: - ETA: 6: - ETA: 6: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 59s - ETA: 58 - ETA: 57 - ETA: 56 - ETA: 55 - ETA: 54 - ETA: 53 - ETA: 52 - ETA: 51 - ETA: 49 - ETA: 48 - ETA: 47 - ETA: 46 - ETA: 45 - ETA: 44 - ETA: 42 - ETA: 41 - ETA: 40 - ETA: 39 - ETA: 38 - ETA: 37 - ETA: 36 - ETA: 35 - ETA: 34 - ETA: 33 - ETA: 31 - ETA: 30 - ETA: 29 - ETA: 28 - ETA: 27 - ETA: 26 - ETA: 25 - ETA: 24 - ETA: 23 - ETA: 22 - ETA: 20 - ETA: 19 - ETA: 18 - ETA: 17 - ETA: 16 - ETA: 15 - ETA: 14 - ETA: 13 - ETA: 12 - ETA: 10 - ETA: 9 - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - 343s 1s/step\n",
      "Time of \"predict\": 5 min. 49 sec.\n"
     ]
    }
   ],
   "source": [
    "image_names_train, y_train_true, y_train_pred = predict(model, datagen_inference, 'photos/train')\n",
    "\n",
    "with open('predictions_train.pkl', 'wb') as f:\n",
    "    dill.dump([image_names_train, y_train_true, y_train_pred], f)\n",
    "\n",
    "image_names_valid, y_valid_true, y_valid_pred = predict(model, datagen_inference, 'photos/valid')\n",
    "\n",
    "with open('predictions_valid.pkl', 'wb') as f:\n",
    "    dill.dump([image_names_valid, y_valid_true, y_valid_pred], f)\n",
    "\n",
    "image_names_test, y_test_true, y_test_pred = predict(model, datagen_inference, 'photos/test')\n",
    "\n",
    "with open('predictions_test.pkl', 'wb') as f:\n",
    "    dill.dump([image_names_test, y_test_true, y_test_pred], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini_score(roc_auc):\n",
    "    return 2 * roc_auc - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ROC AUC and GINI:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.9958172697269833"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.9916345394539665"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "roc_auc = roc_auc_score(y_train_true, y_train_pred)\n",
    "gini = gini_score(roc_auc)\n",
    "display('ROC AUC and GINI:', roc_auc, gini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ROC AUC and GINI:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.9224064716894416"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.8448129433788831"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "roc_auc = roc_auc_score(y_valid_true, y_valid_pred)\n",
    "gini = gini_score(roc_auc)\n",
    "display('ROC AUC and GINI:', roc_auc, gini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ROC AUC and GINI:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.8634312434458368"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.7268624868916735"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "roc_auc = roc_auc_score(y_test_true, y_test_pred)\n",
    "gini = gini_score(roc_auc)\n",
    "display('ROC AUC and GINI:', roc_auc, gini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_curves(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    threshold_train,\n",
    "    x_valid,\n",
    "    y_valid,\n",
    "    threshold_valid,\n",
    "    x_test,\n",
    "    y_test,\n",
    "    threshold_test,\n",
    "    curve_type='ROC',\n",
    "    width=666,\n",
    "    height=666\n",
    "):\n",
    "    \n",
    "    trace_train = go.Scatter(\n",
    "        x=x_train,\n",
    "        y=y_train,\n",
    "        mode='lines',\n",
    "        name='Train',\n",
    "        text=threshold_train\n",
    "    )\n",
    "    \n",
    "    trace_valid = go.Scatter(\n",
    "        x=x_valid,\n",
    "        y=y_valid,\n",
    "        mode='lines',\n",
    "        name='Valid',\n",
    "        text=threshold_valid\n",
    "    )\n",
    "    \n",
    "    trace_test = go.Scatter(\n",
    "        x=x_test,\n",
    "        y=y_test,\n",
    "        mode='lines',\n",
    "        name='Test',\n",
    "        text=threshold_test\n",
    "    )\n",
    "\n",
    "    data = [trace_train, trace_valid, trace_test]\n",
    "    \n",
    "    if curve_type == 'ROC':\n",
    "        \n",
    "        x_title = 'FPR'\n",
    "        y_title = 'TPR'\n",
    "        title = 'ROC Curves'\n",
    "        \n",
    "        trace_dot = go.Scatter(\n",
    "            x=[0, 1],\n",
    "            y=[0, 1],\n",
    "            mode='lines',\n",
    "            showlegend=False,\n",
    "            line=dict(\n",
    "                dash='dot'\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        data.append(trace_dot)\n",
    "        \n",
    "    elif curve_type == 'PR':\n",
    "        \n",
    "        x_title = 'Recall'\n",
    "        y_title = 'Precision'\n",
    "        title = 'PR Curves'\n",
    "    \n",
    "    layout = go.Layout(\n",
    "        title=dict(\n",
    "            text=title\n",
    "        ),\n",
    "        hovermode='closest',\n",
    "        width=width,\n",
    "        height=height,\n",
    "        xaxis=dict(\n",
    "            title=dict(\n",
    "                text=x_title\n",
    "            )\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            title=dict(\n",
    "                text=y_title\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    fig = go.Figure(data=data, layout=layout)\n",
    "\n",
    "#     fig.show()\n",
    "    pyo.plot(fig, filename='{}_curves.html'.format(curve_type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_train, tpr_train, roc_thresholds_train = roc_curve(y_train_true, y_train_pred)\n",
    "fpr_valid, tpr_valid, roc_thresholds_valid = roc_curve(y_valid_true, y_valid_pred)\n",
    "fpr_test, tpr_test, roc_thresholds_test = roc_curve(y_test_true, y_test_pred)\n",
    "plot_curves(\n",
    "    fpr_train,\n",
    "    tpr_train,\n",
    "    roc_thresholds_train,\n",
    "    fpr_valid,\n",
    "    tpr_valid,\n",
    "    roc_thresholds_valid,\n",
    "    fpr_test,\n",
    "    tpr_test,\n",
    "    roc_thresholds_test\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_train, precision_train, pr_thresholds_train = precision_recall_curve(y_train_true, y_train_pred)\n",
    "recall_valid, precision_valid, pr_thresholds_valid = precision_recall_curve(y_valid_true, y_valid_pred)\n",
    "recall_test, precision_test, pr_thresholds_test = precision_recall_curve(y_test_true, y_test_pred)\n",
    "plot_curves(\n",
    "    recall_train,\n",
    "    precision_train,\n",
    "    pr_thresholds_train,\n",
    "    recall_valid,\n",
    "    precision_valid,\n",
    "    pr_thresholds_valid,\n",
    "    recall_test,\n",
    "    precision_test,\n",
    "    pr_thresholds_test,\n",
    "    curve_type='PR'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PR Train: 0.5401038102068326\n",
      "PR Valid: 0.5017587425002399\n",
      "PR Test: 0.40754415134797234\n"
     ]
    }
   ],
   "source": [
    "print('PR Train:', auc(recall_train, precision_train, reorder=True))\n",
    "print('PR Valid:', auc(recall_valid, precision_valid, reorder=True))\n",
    "print('PR Test:', auc(recall_test, precision_test, reorder=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.6",
   "language": "python",
   "name": "python3.6.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
