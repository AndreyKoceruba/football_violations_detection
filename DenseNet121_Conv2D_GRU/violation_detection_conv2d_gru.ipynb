{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "import datetime\n",
    "import os\n",
    "import shutil\n",
    "import dill\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import Sequence, to_categorical\n",
    "from keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator\n",
    "from keras.applications.densenet import DenseNet121\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import GlobalAveragePooling2D, Dense, Dropout, Activation\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, TensorBoard\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, precision_recall_curve, auc\n",
    "from sklearn.neighbors.kde import KernelDensity\n",
    "from matplotlib import pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import plotly.offline as pyo\n",
    "pyo.init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoStream:\n",
    "    \n",
    "    def __init__(self, filepath):\n",
    "        self.cap = cv2.VideoCapture(filepath)\n",
    "        if not self.cap.isOpened():\n",
    "            raise Exception('Video stream doesn\\'t open!')\n",
    "    \n",
    "    def __enter__(self):\n",
    "        return self.cap\n",
    "        \n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        self.cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShortVideoWarning(UserWarning):\n",
    "    \n",
    "    def __init__(self, message):\n",
    "        super().__init__()\n",
    "        self.message = message\n",
    "        \n",
    "    def __str__(self):\n",
    "        return self.message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_ids(filename):\n",
    "    ids = []\n",
    "    classes = []\n",
    "    with open(filename) as f:\n",
    "        next(f)\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            id_, class_ = line.split(',')\n",
    "            ids.append(id_)\n",
    "            classes.append(class_)\n",
    "    return ids, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids, train_classes = read_ids('../IDs/train.csv')\n",
    "valid_ids, valid_classes = read_ids('../IDs/valid.csv')\n",
    "test_ids, test_classes = read_ids('../IDs/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageSequenceGenerator(Sequence):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        videos,\n",
    "        ids,\n",
    "        classes,\n",
    "        class_names,\n",
    "        target_size=(224, 224),\n",
    "        fps=8,\n",
    "        sequence_time=3,\n",
    "        shift_time=1,\n",
    "        batch_size=8,\n",
    "        shuffle=True,\n",
    "        seed=None,\n",
    "        fit_eval=True\n",
    "    ):\n",
    "        self.videos = videos\n",
    "        self.ids = ids\n",
    "        self.classes = classes\n",
    "        self.class_names = class_names\n",
    "        self.target_size = target_size\n",
    "        self.fps = fps\n",
    "        self.sequence_time = sequence_time\n",
    "        self.shift_time = shift_time\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.seed = seed\n",
    "        self.fit_eval = fit_eval\n",
    "        \n",
    "        self.timesteps = self.fps * self.sequence_time\n",
    "        self.shift_frames = self.fps * self.shift_time\n",
    "        \n",
    "        self.skip_id = []\n",
    "        self.start_positions = []\n",
    "        self.indexes = None\n",
    "        \n",
    "        self.__check_videos_total_time()\n",
    "        self.__make_start_positions()\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __check_videos_total_time(self):\n",
    "        all_ids = os.listdir(self.videos)\n",
    "        self.skip_id = []\n",
    "        for id_ in all_ids:\n",
    "            video_path = os.path.join(self.videos, id_)\n",
    "            with VideoStream(video_path) as cap:\n",
    "                frames_cnt = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "                fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "                total_time = frames_cnt / fps\n",
    "                if total_time < self.sequence_time:\n",
    "                    self.skip_id.append(id_)\n",
    "                    warn_message = 'Video {} has time {} less than sequence_time {} and will be skipped'.format(\n",
    "                        id_,\n",
    "                        total_time,\n",
    "                        self.sequence_time\n",
    "                    )\n",
    "                    warnings.warn(ShortVideoWarning(warn_message))\n",
    "    \n",
    "    def __next_frame_step(self, fps):\n",
    "        if self.fps is None:\n",
    "            next_frame_step = 1\n",
    "        else:\n",
    "            next_frame_step = int(np.ceil(fps / self.fps))\n",
    "        return next_frame_step\n",
    "    \n",
    "    def __make_start_positions(self):\n",
    "        for id_ in self.ids:\n",
    "            if id_ not in self.skip_id:\n",
    "                video_path = os.path.join(self.videos, id_)\n",
    "                with VideoStream(video_path) as cap:\n",
    "                    frames_cnt = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "                    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "                    next_frame_step = self.__next_frame_step(fps)\n",
    "                    start_positions = range(\n",
    "                        0,\n",
    "                        frames_cnt - self.timesteps * next_frame_step,\n",
    "                        self.shift_frames * next_frame_step\n",
    "                    )\n",
    "                    for start_position in start_positions:\n",
    "                        self.start_positions.append((id_, start_position))\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        self.indexes = np.arange(len(self.start_positions))\n",
    "        if self.shuffle:\n",
    "            if self.seed is not None:\n",
    "                np.random.seed(self.seed)\n",
    "            np.random.shuffle(self.indexes)\n",
    "    \n",
    "    def __len__(self):\n",
    "        length = int(np.ceil(len(len(self.start_positions)) / float(self.batch_size)))\n",
    "        return length\n",
    "    \n",
    "    def __get_x(self, batch_start_positions):\n",
    "        batch_x = []\n",
    "        for id_, start_position in tqdm_notebook(batch_start_positions):\n",
    "            video_path = os.path.join(self.videos, id_)\n",
    "            with VideoStream(video_path) as cap:\n",
    "                fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "                next_frame_step = self.__next_frame_step(fps)\n",
    "                frame_sequence = []\n",
    "                current_pos = start_position\n",
    "                for i in range(self.timesteps):\n",
    "                    cap.set(cv2.CAP_PROP_POS_FRAMES, current_pos)\n",
    "                    ret, frame = cap.read()\n",
    "                    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                    frame = cv2.resize(frame, self.target_size)\n",
    "                    frame_sequence.append(frame)\n",
    "                    current_pos += next_frame_step\n",
    "                frame_sequence = np.array(frame_sequence)\n",
    "            batch_x.append(frame_sequence)\n",
    "        batch_x = np.array(batch_x)\n",
    "        return batch_x\n",
    "    \n",
    "    def __get_y(self, batch_start_positions):\n",
    "        batch_y = []\n",
    "        for id_, start_position in batch_start_positions:\n",
    "            index = self.ids.index(id_)\n",
    "            batch_y.append(self.classes[index])\n",
    "        batch_y = np.array(batch_y)\n",
    "        batch_y = to_categorical(batch_y, num_classes=len(self.class_names))\n",
    "        return batch_y\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        indexes = self.indexes[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_start_positions = [self.start_positions[i] for i in indexes]\n",
    "        batch_x = self.__get_x(batch_start_positions)\n",
    "        if self.fit_eval:\n",
    "            batch_y = self.__get_y(batch_start_positions)\n",
    "            return batch_x, batch_y\n",
    "        return batch_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = ImageSequenceGenerator('../videos', train_ids, train_classes, ['0', '1'], seed=1992, fit_eval=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.6",
   "language": "python",
   "name": "python3.6.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
